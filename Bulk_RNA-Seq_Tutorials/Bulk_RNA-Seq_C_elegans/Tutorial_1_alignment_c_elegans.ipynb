{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulk RNA-Seq Analysis Training Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This short tutorial demonstrates how to run an RNA-Seq workflow using a subsampling Caenorhabditis elegans dataset. Steps in the workflow include read trimming, read QC, read mapping, and counting mapped reads per gene to quantitate gene expression. This tutorial workflow uses truncated and partial run data from the Rochester JD et al. project.\n",
    "\n",
    "This tutorial can take over 17 minutes to run the code fully, with a `ml.t3.medium` instance, because of the limited memory we are using a subsampled dataset from Rochester JD et al. from chr I and 1,000,000 reads each sample. This is part of the reason we have a short and easy introductory tutorial, but provide a longer more full tutorial for those interested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> NOTE: This Jupyter Notebook was developed to run within a customized container on AWS with all software and tools pre-configured. If running without this customized container, you will need to install tools using the Miniforge environment setup instructions below before moving on to Step 2.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Container: Install Miniforge and Workflow Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miniforge is a lightweight Conda distribution that offers a streamlined installation process and efficient package management. It provides access to a vast repository of packages.\n",
    "\n",
    "Conda packages and environments are useful for several reasons. Conda packages contain metadata. This metadata includes information about what other programs the given software needs to be installed, in order to run. When installing a package with Conda, those other packages are automatically also installed. In this way, the user does not have to worry about manually installing each dependency. This makes installation quick and simple.\n",
    "\n",
    "These packages are installed inside of environments, which are simply folders within the local installation of Conda. This has several benefits. Local installation means easier installation for non-admin users who may not have access to all system directories. Each environment can hold specific software with specific versions, and it easy to swap to different environments. In addition, the environments themselves are portable, as each environment contains a manifest on how to recreate that environment.\n",
    "\n",
    "Miniforge itself is a Conda package manager, this means it requires Conda in order to work. It is used to install and update Conda packages, which it gets from a ‘channel’, or repository. It is an alternative to the native Conda package manager. It is often used for reasons of speed.\n",
    "\n",
    "Bioconda is a ‘channel’, or repository, that the Mambaforge package manager can download packages from. It is a repository of Conda packages that are related to biology. These packages are versions of popular biology software that are curated and uploaded by contributing users.\n",
    "\n",
    "The following code performs these steps:\n",
    "- Downloads Miniforge or Mambaforge (you can use either based on preference)\n",
    "- Installs Miniforge (or Mambaforge) - no need to install conda since mamba will be available immediately\n",
    "- Using miniforge and bioconda, installs the tools that will be used in this tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Tip: If using the Miniforge install, run the following code cells by removing the %%script false command. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Download Miniforge or Mambaforge (you can use either based on preference)\n",
    "!curl -L -O https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh > /dev/null 2>&1\n",
    "\n",
    "# Install Miniforge (or Mambaforge) - no need to install conda since mamba will be available immediately\n",
    "!bash Miniforge3-$(uname)-$(uname -m).sh -b -u -p $HOME/miniforge > /dev/null 2>&1\n",
    "!date +\"%T\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, using miniforge and bioconda, install the tools that will be used in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Update PATH to point to the Miniforge (or Mambaforge) bin files\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + os.environ[\"HOME\"]+\"/miniforge/bin\"\n",
    "\n",
    "# Now use mamba directly to install your software packages\n",
    "!mamba install -y -c conda-forge -c bioconda trimmomatic fastqc multiqc sql-magic entrez-direct gffread parallel-fastq-dump sra-tools pyathena samtools star rsem subread pigz -y > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------\n",
    "## If running from a container, as noted above, start with <b> STEP 2 </b> below:\n",
    "## STEP 2: Define Threads & Setup Directory Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a set of directories to store the reads, reference sequence files, and output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd $HOMEDIR\n",
    "!echo $PWD\n",
    "!mkdir -p data_1\n",
    "!mkdir -p data_1/trunc_rawfastq\n",
    "!mkdir -p data_1/trimmed\n",
    "!mkdir -p data_1/fastqc\n",
    "!mkdir -p data_1/fastqc_samples/\n",
    "!mkdir -p data_1/reference\n",
    "!mkdir -p data_1/raw_fastq\n",
    "!mkdir -p data_1/aligned_bam\n",
    "!mkdir -p data_1/rsem_reference/celegans_rsem_reference\n",
    "!mkdir -p data_1/rsem_output\n",
    "!mkdir -p data_1/reference/STAR_index\n",
    "!mkdir -p data_1/gene_counts\n",
    "!mkdir -p data_1/multiqc_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the number of available threads based on the VM.\n",
    "\n",
    "This is useful for later tools such as trimmomatic, or STAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "THREADS = max(1, num_cores - 1)\n",
    "\n",
    "print(\"Number of threads:\", THREADS)\n",
    "os.environ[\"THREADS\"] = str(THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: Downloading relevant files\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3.1: Finding run accession numbers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code retrieves the SRR IDs associated with project PRJNA625528 from the NCBI database and saves them to a .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!esearch -db sra -query \"PRJNA625528\" | efetch -format runinfo | cut -d',' -f1 | tail -n +2 > all_accs.txt\n",
    "!grep -E \"SRR11550221|SRR11550223|SRR11550225|SRR11550227|SRR11550229|SRR11550231\" all_accs.txt > accs.txt\n",
    "!cat accs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3.2: Download subsampling FASTQ files from S3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for this tutorial to run quickly, we will only analyze 1,000,000 reads from each of the six samples in PRJNA625528. These subsampled files have been posted on a publicly accessible S3 bucket.\n",
    "\n",
    "The code will connect to the S3 bucket and download the paired-end FASTQ files for each SRR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load SRR IDs from accs.txt (if available)\n",
    "with open('accs.txt', 'r') as f:\n",
    "    accs = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for acc in accs:\n",
    "    !wget -P data_1/raw_fastq/ https://nigms-sandbox.s3.us-east-1.amazonaws.com/bulk-scRNAseq/fastqfiles/subsampledchr1_celegans_{acc}.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3.3: Download reference genome and annotation files that will be used by STAR and RSEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step downloads and unzips reference files for the C. elegans genome and annotations needed by STAR. These reference files will be used by STAR to align RNA-seq reads during the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://nigms-sandbox.s3.us-east-1.amazonaws.com/bulk-scRNAseq/reference/celegans_genome.fa -O data_1/reference/celegans_genome.fa\n",
    "!wget https://nigms-sandbox.s3.us-east-1.amazonaws.com/bulk-scRNAseq/reference/celegans_annotation.gtf -O data_1/reference/celegans_annotation.gtf\n",
    "!wget https://nigms-sandbox.s3.us-east-1.amazonaws.com/bulk-scRNAseq/reference/celegans_feature_table.txt -O data_1/reference/celegans_feature_table.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use samtools to extract only chr1 from the reference genome\n",
    "!samtools faidx data_1/reference/celegans_genome.fa \"I\" > data_1/reference/celegans_genome_chr1.fa\n",
    "\n",
    "# Subset the GTF file to include only chr1 annotations\n",
    "!grep \"^I\\s\" data_1/reference/celegans_annotation.gtf > data_1/reference/celegans_annotation_chr1.gtf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3.4: Copy data file for Trimmomatic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of trimmomatics functions is to trim sequence machine specific adapter sequences. These are usually within the trimmomatic installation directory in a folder called adapters.\n",
    "\n",
    "Directories of packages within conda installations can be confusing, so in the case of using conda with trimmomatic, it may be easier to simply download or create a file with the relevant adapter sequencecs and store it in an easy to find directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://nigms-sandbox.s3.us-east-1.amazonaws.com/bulk-scRNAseq/reference/TruSeq3-SE.fa -O data_1/trimmed/TruSeq3-SE.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4: Run Trimmomatic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trimmomatic will trim off any adapter sequences or low quality sequence it detects in the FASTQ files.\n",
    "\n",
    "Trimmomatic takes an input, in this case a forward and reverse FASTQ file, and the user names the outputs. In this case the first two outputs are the ‘paired’ and ‘orphaned’ trimmed files for the forward reads. The second two are the ‘paired’ and ‘orphaned’ trimmed files for the reverse reads.\n",
    "\n",
    "Paired in this case means the forward and reverse sequences were able to be aligned to each other after trimming. Orphaned, or unpaired, typically means one of the reads was discarded as a result of trimming, and only the forward or reverse read survived.\n",
    "\n",
    "Here we take only the file with paired reads, as there are only a few orphaned reads, and including orphaned reads can complicate different downstream analyses. Unless there is a significant amount of them, or a specific reason to use them, it is generally easier to discard unpaired reads. Also in the interest of simplicity and speed, we proceed in further steps with just using the paired-end reads of just the forward-end read files, which in this context is sufficient, however in different contexts, using both forward and reverse is often preferable.\n",
    "\n",
    "The last part of the command specifies how the trimming is done: `ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36`\n",
    "\n",
    "<u>In greater detail</u>:\n",
    "\n",
    "`ILLUMINACLIP:TruSeq3-PE.fa` refers to which adapters should be cut from the reads.\n",
    "\n",
    "`2:30:10:2` refers to various metrics, which are recommended defaults.\n",
    "\n",
    "`2` refers to the seed mismatch. This refers to the amount of mismatches a 'seed' may have in aligning to a possible adapter.\n",
    "\n",
    "`30` refers to the palindrome clip threshold. This refers to the similarity score. If forward and reverse reads, after having an adapter attached to them, are greater than this score, trimming of adapter fragments will be performed. Forward reads are clipped, and reverse reads dropped.\n",
    "\n",
    "`10` refers to the simple clip threshold. The basic, and alternative method to palindromic searching for adapters. Adapters are tested against reads and if sufficiently matched (above the threshold, in this case, 10), they are clipped.\n",
    "\n",
    "`2` refers to the minimum adapter fragment length in palindrome mode.\n",
    "\n",
    "`LEADING:3` refers to trimming bases from the start of a read. Bases at the start of a read will continue to be trimmed, sequentially, as long as the bases remain below a PHRED score of 3.\n",
    "\n",
    "`TRAILING:3` refers to the same as above, but at the end of a read.\n",
    "\n",
    "`MINLEN:36`, the read is discarded if below this length.\n",
    "\n",
    "Greater information about parameters can be found in the trimmomatic documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat accs.txt | xargs -I {} \\\n",
    "trimmomatic SE -threads $THREADS \\\n",
    "data_1/raw_fastq/subsampledchr1_celegans_{}.fastq data_1/trimmed/{}_trimmed.fastq \\\n",
    "ILLUMINACLIP:data_1/trimmed/TruSeq3-SE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5: Run FastQC\n",
    "FastQC is an invaluable tool that allows you to evaluate whether there are problems with a set of reads. For example, it will provide a report of whether there is any bias in the sequence composition of the reads.\n",
    "\n",
    "Because jupyter is at its core a python editor, we can use python code and html support to display results in-line.\n",
    "\n",
    "FastQC looks for different characteristics of quality in reads. It is very rare that every metric will pass. In many cases, they serve as warnings, which should be compared to the context of the experiment. For instance, here, per base sequence content, sequence length distribution, sequence duplication levels, and overrepresented sequences all throw warnings. Per base sequence content routinely fails in RNA-sequencing in the first 15~ or so bases due to biased fragmentation. In most of our samples, this is where we see the failure (20% or more difference between A/T or G/C), and so is not unexpected. The overrepresented sequences can be BLASTed to show the majority of them are ribosomal RNA. Ribosomal RNA contamination is also common and will not be indexed later, and so not a large concern. Other metrics look good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run FastQC\n",
    "!cat accs.txt | xargs -P $THREADS -I {} fastqc data_1/trimmed/{}_trimmed.fastq -o data_1/fastqc_samples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src='./data_1/fastqc_samples/SRR11550221_trimmed_fastqc.html', width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 6: Run MultiQC\n",
    "MultiQC reads in the FastQC reports and generate a compiled report for all the analyzed FASTQ files.\n",
    "\n",
    "Being able to use python with bash also means we can seamlessly use popular python packages, such as pandas, to interact with or view the files we create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!multiqc -f -o data_1/multiqc_samples/ data_1/fastqc_samples/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 7: Preparing the STAR-Compatible RSEM Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided code snippet demonstrates the process of preparing a reference genome and annotation files for RNA-Seq analysis using RSEM and STAR. The initial command, rsem-prepare-reference, creates a reference index for the C. elegans genome based on the provided GTF annotation file (celegans_annotation.gtf). This index, along with the reference genome sequence (celegans_genome.fa), is essential for quantifying gene and isoform expression using RSEM. The --star option ensures compatibility with STAR, a popular transcriptome aligner.\n",
    "\n",
    "However, the subsequent STAR genome generation step encounters a warning due to an excessively large --genomeSAindexNbases parameter. This parameter controls the size of the genome's suffix array index, which is used for efficient alignment. If the parameter is too large for the given genome size, it can lead to segmentation faults during the mapping process. To address this issue, the code adjusts the --genomeSAindexNbases parameter to 12, which is more appropriate for the C. elegans genome. This modification ensures that the STAR genome generation process completes successfully without errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rsem-prepare-reference --gtf data_1/reference/celegans_annotation_chr1.gtf --star -p $THREADS data_1/reference/celegans_genome_chr1.fa celegans_reference > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!STAR  --runThreadN $THREADS  --runMode genomeGenerate  --genomeDir .  --genomeFastaFiles data_1/reference/celegans_genome_chr1.fa  --sjdbGTFfile data_1/reference/celegans_annotation_chr1.gtf  --sjdbOverhang 100  --outFileNamePrefix celegans_reference  --genomeSAindexNbases 10 > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 8: Automated RNA-seq Quantification with RSEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code automates the process of quantifying gene expression from RNA-seq data using RSEM. It reads a list of SRR accession numbers from a text file, iterates over each accession, and executes the RSEM command to calculate gene expression levels. The code assumes that the trimmed FASTQ files for each SRR are located in a specified directory (data_1/trimmed/) and uses a previously generated reference index (celegans_reference). The output files are saved in the data_1/rsem_output directory, with filenames based on the corresponding SRR accession number. This script simplifies the workflow for analyzing multiple RNA-seq samples using RSEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Ensure you've set the path to the RSEM binary\n",
    "with open('accs.txt', 'r') as f:\n",
    "    srr_accessions = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "# Define the output directory\n",
    "output_dir = \"data_1/rsem_output\"\n",
    "\n",
    "for srr in srr_accessions:\n",
    "    os.system(f\"rsem-calculate-expression -p $THREADS --star \"\n",
    "              f\"data_1/trimmed/{srr}_trimmed.fastq celegans_reference \"\n",
    "              f\"{output_dir}/{srr}celegans > /dev/null\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 9: Report the top 10 most highly expressed genes in the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 most highly expressed genes in each wild-type sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to RSEM results directory\n",
    "rsem_results_dir = 'data_1/rsem_output'\n",
    "\n",
    "# Loop through each file in accs.txt\n",
    "for srr_id in open('accs.txt'):\n",
    "    srr_id = srr_id.strip()  # Remove newline character\n",
    "    rsem_result_file = f'{rsem_results_dir}/{srr_id}celegans.genes.results'\n",
    "\n",
    "    # Load the RSEM results into a Pandas DataFrame\n",
    "    df = pd.read_csv(rsem_result_file, sep='\\t')\n",
    "\n",
    "    # Sort the DataFrame by TPM values in descending order and get the top 10 genes\n",
    "    top_10_genes = df.sort_values(by='TPM', ascending=False).head(10)\n",
    "\n",
    "    # Print the top 10 genes with their TPM values\n",
    "    print(f\"Top 10 Genes by TPM for {srr_id}:\")\n",
    "    print(top_10_genes[['gene_id', 'TPM']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 most highly expressed genes in the double lysogen samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 10: Report the expression of WBGene00004512 for each file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `grep` to report the expression in the wild-type sample. The fields in the RSEM `genes.results` file are as follows. The level of expression is reported in the Transcripts Per Million (`TPM`) and number of reads (`NumReads`) fields:  \n",
    "- `Name`    \n",
    "- `Length`\n",
    "- `EffectiveLength`\n",
    "- `TPM`\n",
    "- `NumReads`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to RSEM results directory\n",
    "rsem_results_dir = 'data_1/rsem_output'\n",
    "\n",
    "# Target gene ID\n",
    "target_gene = 'WBGene00004512'\n",
    "\n",
    "# Loop through each file in accs.txt\n",
    "for srr_id in open('accs.txt'):\n",
    "    srr_id = srr_id.strip()  # Remove newline character\n",
    "    rsem_result_file = f'{rsem_results_dir}/{srr_id}celegans.genes.results'\n",
    "\n",
    "    # Load the RSEM results into a Pandas DataFrame\n",
    "    df = pd.read_csv(rsem_result_file, sep='\\t')\n",
    "\n",
    "    # Filter for the target gene\n",
    "    target_gene_data = df[df['gene_id'] == target_gene]\n",
    "\n",
    "    # Print the target gene's TPM value for the SRR ID\n",
    "    print(f\"TPM for {target_gene} in {srr_id}: {target_gene_data['TPM'].values[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"workflow\">Additional Workflows</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have read counts per gene, feel free to explore the R workflow which creates plots and analyses using these readcount files, or try other alternate workflows for creating read count files, such as using snakemake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[Workflow One (Extended):](Tutorial_1B_Extended_celegans.ipynb) An extended version of workflow one. Once you have got your feet wet, you can retry workflow one with this extended version that covers the entire dataset.\n",
    "\n",
    "[Workflow Two (DEG Analysis):](Tutorial_2_DEG_Analysis_celegans.ipynb) Using Deseq2 and R to conduct clustering and differential gene expression analysis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
